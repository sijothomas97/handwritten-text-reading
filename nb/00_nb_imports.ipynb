{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZrd1z5pbMOe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39882194"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "from collections import namedtuple\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "import collections\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm.notebook import tqdm, trange"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want the result to be reproducible, you will need to set the seed."
      ],
      "metadata": {
        "id": "6061aGw4pM0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SEED = 1234\n",
        "\n",
        "# random.seed(SEED)\n",
        "# np.random.seed(SEED)\n",
        "# torch.manual_seed(SEED)\n",
        "# torch.cuda.manual_seed(SEED)\n",
        "# torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "QrPC2sxvRkvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount to Google drive and unpack your dataset"
      ],
      "metadata": {
        "id": "zSV0OKw4pY14"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-h6147Klo6y",
        "outputId": "8dbed9dd-3412-4562-aae0-2569fd250ab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4B7PKK1Y1FYV"
      },
      "outputs": [],
      "source": [
        "# Unpack the dataset zip file\n",
        "# shutil.unpack_archive(\"/content/drive/MyDrive/MMU/Deep Learning/Assessment/archive.zip\", \"/content/Datasets/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(datasets.ImageFolder('/content/Datasets/Train')), len(datasets.ImageFolder('/content/Datasets/Validation'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0m8vZktKdYW",
        "outputId": "ac4a1e19-3bd8-40d3-9133-3aacb1bd4c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "834036"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking subset from Training and Validation set"
      ],
      "metadata": {
        "id": "FGR7lbkCeVJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a smaller dataset, from the original one to reduce execution time, and saving it to the /content/Datasets/ directory of colab.\n",
        "\n",
        "for folder in os.listdir('/content/Datasets/Train'):\n",
        "  if not os.path.exists('/content/Datasets/sample_datast/Train/'+folder):\n",
        "    os.makedirs('/content/Datasets/sample_datast/Train/'+folder)\n",
        "    for file in os.listdir('/content/Datasets/Train/'+folder)[:100]:\n",
        "      shutil.copy('/content/Datasets/Train/'+folder+'/'+file, '/content/Datasets/sample_datast/Train/'+folder+'/')\n",
        "\n",
        "for folder in os.listdir('/content/Datasets/Validation'):\n",
        "  if not os.path.exists('/content/Datasets/sample_datast/Validation/'+folder):\n",
        "    os.makedirs('/content/Datasets/sample_datast/Validation/'+folder)\n",
        "    for file in os.listdir('/content/Datasets/Validation/'+folder)[:30]:\n",
        "      shutil.copy('/content/Datasets/Validation/'+folder+'/'+file, '/content/Datasets/sample_datast/Validation/'+folder+'/')\n",
        "\n",
        "print('Sample dataset created with 100 images each for every character for Train set and 30 images each for validation set')"
      ],
      "metadata": {
        "id": "gsZ8lOJ3_nFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a test set of images for prediction and saving it to the /content/Datasets directory.\n",
        "if not os.path.exists('/content/Datasets/sample_datast/Test'):\n",
        "  os.makedirs('/content/Datasets/sample_datast/Test')\n",
        "else:\n",
        "  shutil.rmtree('/content/Datasets/sample_datast/Test')\n",
        "\n",
        "for folder in os.listdir('/content/Datasets/Train'):\n",
        "  os.makedirs('/content/Datasets/sample_datast/Test/'+folder)\n",
        "  for file in os.listdir('/content/Datasets/Train/'+folder)[105:106]:\n",
        "    shutil.copy('/content/Datasets/Train/'+folder+'/'+file, '/content/Datasets/sample_datast/Test/'+folder+'/')\n",
        "\n",
        "print('Training sample created successfully')"
      ],
      "metadata": {
        "id": "qAW4U2hgK3Yp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a46300d8-cfd9-4fb4-dd83-a9dbb4180fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training sample created successfully\n"
          ]
        }
      ]
    }
  ]
}